{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ImbalancedLearningRegression"
      ],
      "metadata": {
        "id": "E15mmc_wjbEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install smogn\n",
        "!pip install resreg"
      ],
      "metadata": {
        "id": "B4E196Kdjefx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0QXka8hfid09"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RepeatedKFold, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "from glob import glob\n",
        "import xgboost as xgb\n",
        "import numpy as np\n",
        "import os\n",
        "import itertools as it\n",
        "import smogn\n",
        "import resreg\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "import ImbalancedLearningRegression as iblr\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def balance(train, strategy, c):\n",
        "\n",
        "  train = pd.read_csv(\"train.csv\")\n",
        "\n",
        "  if strategy == \"GN\":\n",
        "    train = iblr.gn(data = train, y = \"0\", samp_method=c[0], pert=c[1],  rel_thres = 0.8)\n",
        "  elif strategy == \"RO\":\n",
        "    train = iblr.ro(data = train, y = \"0\", samp_method=c[0], rel_thres = 0.8)\n",
        "  elif strategy == \"RU\":\n",
        "    train = iblr.random_under(data = train, y = \"0\", samp_method=c[0], rel_thres = 0.8)\n",
        "  elif strategy == \"SG\":\n",
        "    train =  train.dropna()\n",
        "    train = smogn.smoter(data = train, y = train.columns[0], samp_method=c[0], rel_xtrm_type = 'high', rel_thres = 0.8)\n",
        "    train =  train.dropna()\n",
        "  elif strategy == \"SMT\":\n",
        "    train = iblr.smote(data = train, y = \"0\", samp_method=c[0], rel_thres = 0.8)\n",
        "  elif strategy == \"WC\":\n",
        "    X_train = train.drop([train.columns[0]], axis = 1)\n",
        "    y_train  = train[train.columns[0]]\n",
        "    relevance = resreg.pdf_relevance(y_train)\n",
        "    X_wercs, y_wercs = resreg.wercs(X_train, y_train, relevance, over=c[0], under=c[1])\n",
        "    trainWC = np.column_stack((y_wercs, X_wercs))\n",
        "    pd.DataFrame(trainWC).to_csv(\"trainWC.csv\", index=False)\n",
        "    train = pd.read_csv(\"trainWC.csv\")\n",
        "  return train"
      ],
      "metadata": {
        "id": "FCKKAwIUioar"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def repeatedKfold(n_splits=10, n_repeats=2, random_state=42, pipeline=None, param_grid=None) :\n",
        "  rkf = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
        "  all_result = []\n",
        "\n",
        "  strategys = {\"SG\":{\"samp_method\":[\"balance\", \"extreme\"]},\n",
        "                \"RU\":{\"C.perc\":[\"balance\", \"extreme\"]},\n",
        "                \"RO\":{\"C.perc\":[\"balance\", \"extreme\"]},\n",
        "                \"SMT\":{\"C.perc\":[\"balance\", \"extreme\"]},\n",
        "                \"GN\":{\"C.perc\":[\"balance\", \"extreme\"], \"pert\":[0.05, 0.1, 0.5]},\n",
        "                \"WC\":{\"over\":[0.5, 0.8], \"under\":[0.5, 0.8]},\n",
        "                'None': {None}}\n",
        "\n",
        "\n",
        "\n",
        "  path = dataset\n",
        "  head, tail = os.path.split(path)\n",
        "\n",
        "  for strategy in strategys:\n",
        "      data_frame = []\n",
        "      params = strategys[strategy]\n",
        "\n",
        "      keys = sorted(params)\n",
        "\n",
        "      if strategy != \"None\":\n",
        "          combinations = it.product(*(params[Name] for Name in keys))\n",
        "      else:\n",
        "        combinations = ['None']\n",
        "      for c in list(combinations):\n",
        "        score_perc = []\n",
        "        i = 1\n",
        "        for train_index, test_index in rkf.split(X, y):\n",
        "\n",
        "          X_train, X_test = X[train_index], X[test_index]\n",
        "          y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "          train = np.column_stack((y_train, X_train))\n",
        "          pd.DataFrame(train).to_csv(\"train.csv\", index=False)\n",
        "          train = pd.read_csv(\"train.csv\")\n",
        "\n",
        "          if c != 'None':\n",
        "            try:\n",
        "              train = balance(train, strategy, c)\n",
        "            except ValueError:\n",
        "              pass\n",
        "\n",
        "          X_train = train.drop([train.columns[0]], axis = 1)\n",
        "          y_train  = train[train.columns[0]]\n",
        "\n",
        "          if len(X_train) > 10:\n",
        "\n",
        "            grid_search = GridSearchCV(pipeline, cv=rkf, param_grid=param_grid, n_jobs=-1)\n",
        "            grid_search.fit(X_train.values, y_train.values)\n",
        "\n",
        "            y_pred  = grid_search.predict(X_test)\n",
        "\n",
        "            #test = np.column_stack((test_index, y_test))\n",
        "            #pd.DataFrame(test).to_csv('NEW/RO/'+tail+'/Test{}_{}_{}_{}.csv'.format(i, strategy, c, str(pipeline.steps[0][1]).split('(')[0]), index = False)\n",
        "            pred = np.column_stack((test_index, y_pred))\n",
        "            pd.DataFrame(pred).to_csv('/Pred{}_{}_{}_{}.csv'.format(i, strategy, c, str(pipeline.steps[0][1]).split('(')[0]), index = False)\n",
        "\n",
        "            i = i+1"
      ],
      "metadata": {
        "id": "9yADQzTxiqVy"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pipe_generation():\n",
        "  clf_param = dict()\n",
        "  for clf in [BaggingRegressor(DecisionTreeRegressor()), DecisionTreeRegressor(), MLPRegressor(max_iter=200), RandomForestRegressor(), SVR(), XGBRegressor(verbosity=0)]:\n",
        "      clf_param[str(clf).split('(')[0]] = clf\n",
        "\n",
        "  pipes_params = []\n",
        "  for clf,  param_grid in zip([BaggingRegressor(DecisionTreeRegressor()), DecisionTreeRegressor(), MLPRegressor(max_iter=200), RandomForestRegressor(), SVR(), XGBRegressor(verbosity=0)],\n",
        "\n",
        "                   [{'clf__base_estimator__min_samples_split': [20], 'clf__max_samples':[0.5]},\n",
        "                    {'clf__min_samples_split': [20]},\n",
        "                    {'clf__learning_rate_init': [0.1],'clf__momentum': (0.2, 0.7),'clf__tol': (0.01, 0.05)},\n",
        "                    {'clf__n_estimators': [550, 1500], 'clf__max_features': [5]},\n",
        "                    {'clf__gamma': [0.01, 0.001], 'clf__C': [10, 300]},\n",
        "                    {'clf__eta': [0.01], 'clf__max_depth': (10, 15), 'clf__colsample_bytree': (0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9), 'clf__num_round': [25]}]):\n",
        "\n",
        "    configs = []\n",
        "    clf = str(clf).split('(')[0]\n",
        "    for p in param_grid:\n",
        "        aux = p\n",
        "        for i in param_grid[p]:\n",
        "          aux += '+'+str(i)\n",
        "        clf += '|'+aux\n",
        "    configs.append(clf)\n",
        "\n",
        "    for config in configs:\n",
        "\n",
        "      pipeline = Pipeline([('clf', clf_param[config.split('|')[0]])])\n",
        "      params = config.split('|')\n",
        "\n",
        "      param_grid = {}\n",
        "      t, t1 = len(params), 0\n",
        "      for p in range(len(params)):\n",
        "        values = ()\n",
        "        if len(params[p].split('+')) > 2:\n",
        "          a = params[p].split('+')[1:]\n",
        "          for j in a:\n",
        "            if '0.' in j:\n",
        "              values += (float(j),)\n",
        "            else:\n",
        "              values += (int(j),)\n",
        "\n",
        "          param_grid[params[p].split('+')[0]] = values\n",
        "\n",
        "        else:\n",
        "\n",
        "          if t1 == t:\n",
        "            if '0.' in params[p].split('+')[1]:\n",
        "              param_grid[params[p].split('+')[0]] = [params[p].split('+')[1]]\n",
        "            else:\n",
        "              param_grid[params[p].split('+')[0]] = [params[p].split('+')[1]]\n",
        "          elif t1 < t:\n",
        "            for l in params[t1].split('+')[1:]:\n",
        "\n",
        "              if '0.' in l:\n",
        "                param_grid[params[t1].split('+')[0]] = [float(l)]\n",
        "              else:\n",
        "                param_grid[params[t1].split('+')[0]] = [int(l)]\n",
        "\n",
        "        t1 += 1\n",
        "\n",
        "    pipes_params.append([pipeline, param_grid])\n",
        "  return pipes_params"
      ],
      "metadata": {
        "id": "CdeVKgdMiv0S"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_sets = sorted(glob(r'/ds/*.csv'))"
      ],
      "metadata": {
        "id": "nhq58qeFi2hS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipes_params = pipe_generation()\n",
        "\n",
        "for j in pipes_params:\n",
        "    score_ap = []\n",
        "    for i, dataset in enumerate(data_sets):\n",
        "\n",
        "          ds = pd.read_csv(dataset)\n",
        "\n",
        "          path = dataset\n",
        "          head, tail = os.path.split(path)\n",
        "          print(\"=====================\")\n",
        "          print(path)\n",
        "\n",
        "          X = ds.drop([ds.columns[0]], axis = 1)\n",
        "          y = ds[ds.columns[0]]\n",
        "\n",
        "          X = X.to_numpy()\n",
        "          y = y.to_numpy()\n",
        "\n",
        "\n",
        "          pipeline, param_grid = j[0], j[1]\n",
        "          print(str(pipeline.steps[0][1]).split('(')[0])\n",
        "          repeatedKfold(pipeline=pipeline, param_grid=param_grid)\n"
      ],
      "metadata": {
        "id": "EXrlPa9-ixzy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}