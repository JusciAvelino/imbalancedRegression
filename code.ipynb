{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install rpy2"
      ],
      "metadata": {
        "id": "9euYJVbjl9jK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install smogn"
      ],
      "metadata": {
        "id": "4t55S9ZY8ojm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install resreg"
      ],
      "metadata": {
        "id": "WKTJo-Kz81Oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "98hG9t9Z8KRU"
      },
      "outputs": [],
      "source": [
        "import rpy2.robjects as robjects\n",
        "from rpy2.robjects.packages import importr\n",
        "import json\n",
        "from urllib.request import urlopen as urlopen\n",
        "from rpy2.robjects.packages import SignatureTranslatedAnonymousPackage\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RepeatedKFold, GridSearchCV\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "from glob import glob\n",
        "from rpy2.robjects import default_converter\n",
        "from rpy2.robjects import pandas2ri\n",
        "from rpy2.robjects.conversion import Converter, localconverter\n",
        "import rpy2.robjects.numpy2ri\n",
        "from xgboost import XGBRegressor\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import os\n",
        "import itertools as it\n",
        "import smogn\n",
        "import resreg\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "rpy2.robjects.numpy2ri.activate()\n",
        "pandas2ri.activate()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "string = \"\"\"\n",
        "\n",
        "U1 <- function(){\n",
        "\n",
        "  install.packages(\"devtools\")\n",
        "  library(devtools)\n",
        "\n",
        "  \n",
        "  install.packages(c(\"operators\", \"class\", \"fields\", \"ROCR\", \"Hmisc\", \"performanceEstimation\"))\n",
        "\n",
        "  install.packages(c(\"zoo\",\"xts\",\"quantmod\"))\n",
        "\n",
        "  install.packages( \"https://cran.r-project.org/src/contrib/Archive/DMwR/DMwR_0.4.1.tar.gz\", repos=NULL, type=\"source\" )\n",
        "\n",
        "  install_github(\"nunompmoniz/IRon\")\n",
        "  install_github(\"paobranco/UBL\")\n",
        "  install_github(\"rpribeiro/uba\")\n",
        "\n",
        "  library(uba)\n",
        "  library(UBL)\n",
        "  library(IRon)\n",
        "  \n",
        "}\n",
        "\n",
        "\"\"\"\n",
        "powerpack = SignatureTranslatedAnonymousPackage(string, \"powerpack\")\n",
        "\n",
        "powerpack.U1()"
      ],
      "metadata": {
        "id": "89AjChAR0WC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uba = importr(\"uba\")\n",
        "iron = importr(\"IRon\")"
      ],
      "metadata": {
        "id": "FqJP4I_AwAlL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "riXHSw108f-V"
      },
      "outputs": [],
      "source": [
        "def scores(y_test, y_pred):\n",
        "    ph = uba.phi_control(y_test)\n",
        "    ls = uba.loss_control(y_test)\n",
        "    prec = uba.util(y_pred, y_test, ph, ls, uba.util_control(umetric=\"P\", event_thr=0.8))\n",
        "    rec = uba.util(y_pred, y_test, ph, ls, uba.util_control(umetric=\"R\", event_thr=0.8))\n",
        "    sera = iron.sera(y_test, y_pred, phi_trues = uba.phi(y_test,ph))\n",
        "    F1 = uba.util(y_pred, y_test, ph, ls, uba.util_control(umetric=\"Fm\", beta=1, event_thr=0.8))\n",
        "\n",
        "    scores_ = list([mean_squared_error(y_test, y_pred), prec, rec, F1, sera])\n",
        "    return pd.DataFrame(scores_,\n",
        "              columns = [''],\n",
        "              index = ['MSE', 'precision', 'recall', 'fscore', 'sera'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def balance(train, strategy, c):\n",
        "  string = \"\"\"\n",
        "        \n",
        "  library(uba)\n",
        "  library(UBL)\n",
        "  \n",
        "  train <- read.csv(\"/content/train.csv\")\n",
        "\n",
        "  RU <- function(perc){\n",
        "    resample <- RandUnderRegress(X0~., train, thr.rel=0.8, C.perc=perc)\n",
        "  }\n",
        "\n",
        "  RO <- function(perc){\n",
        "    resample <- RandOverRegress(X0~., train, thr.rel=0.8, C.perc=perc)\n",
        "  }\n",
        "\n",
        "  SMT <- function(perc){\n",
        "    resample <- SmoteRegress(X0~., train, thr.rel=0.8, C.perc=perc)\n",
        "  }\n",
        "\n",
        "  GN <- function(perc, pert){\n",
        "    resample <-GaussNoiseRegress(X0~., train, thr.rel=0.8, C.perc=perc, pert=pert)\n",
        "  }\n",
        "  \n",
        "  \"\"\"\n",
        "  powerpack = SignatureTranslatedAnonymousPackage(string, \"powerpack\")\n",
        "  if strategy == \"GN\":\n",
        "    train = pd.DataFrame(powerpack.GN(c[0], c[1]))\n",
        "  elif strategy == \"RO\":\n",
        "    train = pd.DataFrame(powerpack.RO(c[0]))\n",
        "  elif strategy == \"RU\":\n",
        "    train = pd.DataFrame(powerpack.RU(c[0]))\n",
        "  elif strategy == \"SG\":\n",
        "    train = pd.read_csv(\"/content/train.csv\")\n",
        "    train = train.dropna(axis=0)        \n",
        "    train = smogn.smoter(data = train, y = train.columns[0], samp_method=c[0], rel_thres = 0.8)\n",
        "    train = train.dropna(axis=0)        \n",
        "  elif strategy == \"SMT\":\n",
        "    train = pd.DataFrame(powerpack.SMT(c[0]))\n",
        "  elif strategy == \"WC\":\n",
        "    train = pd.read_csv(\"/content/train.csv\")\n",
        "    X_train = train.drop([train.columns[0]], axis = 1)\n",
        "    y_train  = train[train.columns[0]]\n",
        "    relevance = resreg.pdf_relevance(y_train)\n",
        "    X_wercs, y_wercs = resreg.wercs(X_train, y_train, relevance, over=c[0], under=c[1])\n",
        "    trainWC = np.column_stack((y_wercs, X_wercs))\n",
        "    pd.DataFrame(trainWC).to_csv(\"trainWC.csv\", index=False)\n",
        "    train = pd.read_csv(\"/content/trainWC.csv\") \n",
        "  return train"
      ],
      "metadata": {
        "id": "gsHqvYz1AJqv"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def repeatedKfold(n_splits=10, n_repeats=2, random_state=42, pipeline=None, param_grid=None) :\n",
        "  rkf = RepeatedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=random_state)\n",
        "  all_result = []\n",
        "\n",
        "  strategys = {\"RU\":{\"C.perc\":[\"balance\", \"extreme\"]},\n",
        "             \"RO\":{\"C.perc\":[\"balance\", \"extreme\"]},\n",
        "             \"SMT\":{\"C.perc\":[\"balance\", \"extreme\"]},\n",
        "             \"GN\":{\"C.perc\":[\"balance\", \"extreme\"], \"pert\":[0.05, 0.1, 0.5]},\n",
        "             \"SG\":{\"samp_method\":[\"balance\", \"extreme\"]},\n",
        "             \"WC\":{\"over\":[0.5, 0.8], \"under\":[0.5, 0.8]},\n",
        "             'None': {None}}\n",
        "\n",
        "  for strategy in strategys:\n",
        "\n",
        "      data_frame = []\n",
        "      params = strategys[strategy]\n",
        "\n",
        "      keys = sorted(params)\n",
        "\n",
        "      if strategy != \"None\":\n",
        "        combinations = it.product(*(params[Name] for Name in keys))\n",
        "      else:\n",
        "        combinations = ['None']\n",
        "      for c in list(combinations):\n",
        "        score_perc = []\n",
        "        for train_index, test_index in rkf.split(X, y):\n",
        "          \n",
        "          X_train, X_test = X[train_index], X[test_index]\n",
        "          y_train, y_test = y[train_index], y[test_index]\n",
        "          \n",
        "          train = np.column_stack((y_train, X_train))\n",
        "          pd.DataFrame(train).to_csv(\"train.csv\", index=False)\n",
        "          train = pd.read_csv(\"/content/train.csv\")\n",
        "          \n",
        "          if c != 'None':\n",
        "            train = balance(train, strategy, c)\n",
        "          \n",
        "          X_train = train.drop([train.columns[0]], axis = 1)\n",
        "          y_train  = train[train.columns[0]]\n",
        "\n",
        "          X_train = X_train.to_numpy()\n",
        "          y_train = y_train.to_numpy()\n",
        "          \n",
        "          grid_search = GridSearchCV(pipeline, cv=rkf, param_grid=param_grid)\n",
        "          grid_search.fit(X_train, y_train)\n",
        "          y_pred  = grid_search.predict(X_test)\n",
        "\n",
        "          path = dataset\n",
        "          head, tail = os.path.split(path)\n",
        "\n",
        "          test = np.column_stack((test_index, y_test))\n",
        "          pred = np.column_stack((test_index, y_pred))\n",
        "        \n",
        "\n",
        "          score_perc.append(scores(y_test, y_pred).T) \n",
        "\n",
        "        df = pd.concat(score_perc)\n",
        "        values = [tail, \n",
        "                  str(df.precision.mean().round(3)[0])+ \"({})\".format(df.precision.std().round(3)),\n",
        "                  str(df.recall.mean().round(3)[0])+ \"({})\".format(df.recall.std().round(3)),\n",
        "                  str(df.MSE.mean().round(3))+ \"({})\".format(df.MSE.std().round(3)),\n",
        "                  str(df.fscore.mean().round(3)[0])+ \"({})\".format(df.fscore.std().round(3)),\n",
        "                  str(df.sera.mean().round(3)[0])+ \"({})\".format(df.sera.std().round(3))]\n",
        "\n",
        "        scores_df = pd.DataFrame([values], columns=[\"Dataset\", \"Precision\", \"Recall\", \"MSE\", \"Fscore\", \"SERA\"])\n",
        "\n",
        "        if len(keys) > 1:\n",
        "          scores_df[keys[0]]=c[0]\n",
        "          scores_df[keys[1]]=c[1]\n",
        "          scores_df['strategy']=strategy           \n",
        "        else:\n",
        "          scores_df[keys[0]]=c[0]\n",
        "          scores_df['strategy']=strategy\n",
        "\n",
        "        data_frame.append(scores_df)\n",
        "      data_frame = pd.concat(data_frame)\n",
        "      data_frame.to_csv('/content/result_{}_{}.csv'.format(strategy, str(pipeline.steps[0][1]).split('(')[0]), index = False)\n",
        "      all_result.append(data_frame)\n",
        "  return all_result"
      ],
      "metadata": {
        "id": "PveysMspBecc"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pipe_generation():\n",
        "  clf_param = dict()\n",
        "  for clf in [DecisionTreeRegressor()]:\n",
        "    clf_param[str(clf).split('(')[0]] = clf\n",
        "\n",
        "  pipes_params = []\n",
        "  for clf,  param_grid in zip([DecisionTreeRegressor(), MLPRegressor(max_iter=200), RandomForestRegressor(), SVR(), XGBRegressor(silent=True)],\n",
        "                               \n",
        "                  [ {'clf__min_samples_split': [20]},\n",
        "                   {'clf__learning_rate_init': [0.1],'clf__momentum': (0.2, 0.7),'clf__tol': (0.01, 0.05)},\n",
        "                   {'clf__n_estimators': [550, 1500], 'clf__max_features': [5]},\n",
        "                   {'clf__gamma': [0.01, 0.001], 'clf__C': [10, 300]},\n",
        "                   {'clf__eta': [0.01], 'clf__max_depth': (10, 15), 'clf__colsample_bytree': (0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9), 'clf__num_round': [25]}]):\n",
        "\n",
        "    configs = []\n",
        "    clf = str(clf).split('(')[0]\n",
        "    for p in param_grid:\n",
        "        aux = p\n",
        "        for i in param_grid[p]:\n",
        "          aux += '+'+str(i)\n",
        "        clf += '|'+aux\n",
        "    configs.append(clf)\n",
        "  \n",
        "    for config in configs:\n",
        "    \n",
        "      pipeline = Pipeline([('clf', clf_param[config.split('|')[0]])])\n",
        "      params = config.split('|')\n",
        "    \n",
        "      param_grid = {}\n",
        "      t, t1 = len(params), 0\n",
        "      for p in range(len(params)):\n",
        "        values = ()\n",
        "        if len(params[p].split('+')) > 2:\n",
        "          a = params[p].split('+')[1:]\n",
        "          for j in a:\n",
        "            if '0.' in j:\n",
        "              values += (float(j),)\n",
        "            else:\n",
        "              values += (int(j),)\n",
        "          \n",
        "          param_grid[params[p].split('+')[0]] = values\n",
        "        \n",
        "        else:\n",
        "    \n",
        "          if t1 == t:   \n",
        "            if '0.' in params[p].split('+')[1]:\n",
        "              param_grid[params[p].split('+')[0]] = [params[p].split('+')[1]]\n",
        "            else:\n",
        "              param_grid[params[p].split('+')[0]] = [params[p].split('+')[1]]\n",
        "          elif t1 < t:\n",
        "            for l in params[t1].split('+')[1:]:\n",
        "\n",
        "              if '0.' in l:\n",
        "                param_grid[params[t1].split('+')[0]] = [float(l)]\n",
        "              else:\n",
        "                param_grid[params[t1].split('+')[0]] = [int(l)]\n",
        "\n",
        "        t1 += 1\n",
        "  \n",
        "    pipes_params.append([pipeline, param_grid]) \n",
        "  return pipes_params"
      ],
      "metadata": {
        "id": "xswJWzL0-_e5"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone 'https://github.com/JusciAvelino/imbalancedRegression.git'"
      ],
      "metadata": {
        "id": "B-LyMlL2FXpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dhRTm4R49_rE"
      },
      "outputs": [],
      "source": [
        "data_sets = sorted(glob(r'/content/imbalancedRegression/data/*'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVxW082-8qoE"
      },
      "outputs": [],
      "source": [
        "score_ap = []\n",
        "for i, dataset in enumerate(data_sets):\n",
        "  ds = pd.read_csv(dataset)\n",
        "\n",
        "  path = dataset\n",
        "  head, tail = os.path.split(path)\n",
        "  print(\"=====================\")\n",
        "  \n",
        "  X = ds.drop(['Unnamed: 0', ds.columns[1]], axis = 1)\n",
        "  y = ds[ds.columns[1]]\n",
        "\n",
        "  X = X.to_numpy()\n",
        "  y = y.to_numpy()\n",
        "\n",
        "  pipes_params = pipe_generation()\n",
        "  for j in pipes_params:\n",
        "    pipeline, param_grid = j[0], j[1]\n",
        "    print(str(pipeline.steps[0][1]).split('(')[0])\n",
        "    score_all = pd.concat(repeatedKfold(pipeline=pipeline, param_grid=param_grid))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "code.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}