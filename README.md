# Introduction

This file is discribes the methodology used to perform the experiments presented in: **Resampling strategies for imbalanced regression: a survey and empirical analysis**.

# Contents
This file contains:
- **resampling.ipynb** the code with resampling.
- **none.ipynb** the code without resampling.
- **appendices** with all the results:
  - **Appendix A**: Default hyperparameters and descriptions.
  - **Appendix B**: Results by dataset for better configuration of learning models and resampling strategies.
  - **Appendix C**: Average number of training examples generated by each resampling strategy.
  - **Appendix D**: Evolution of the best F1-score for each dataset characteristic.
- **data** with the 30 datasets. The main characteristics of the data are:


| **Datasets**          | **N**   | **p.total** | **p.nom** | **p.num** | **nRare** | **IR** | **% Rare** |
|-----------------------|---------|-------------|-----------|-----------|------------|--------|------------|
| wine-quality          | 6497    | 11          | 0         | 11        | 1523       | 0.306  | 23.4       |
| analcatdata-apnea3    | 450     | 11          | 0         | 11        | 103        | 0.297  | 22.9       |
| meta                  | 528     | 65          | 0         | 65        | 108        | 0.257  | 20.5       |
| cocomo-numeric        | 60      | 56          | 0         | 56        | 10         | 0.200  | 16.7       |
| Abalone               | 4177    | 8           | 1         | 7         | 679        | 0.194  | 16.3       |
| a3                    | 198     | 11          | 3         | 8         | 32         | 0.193  | 16.2       |
| forestFires           | 517     | 12          | 0         | 12        | 79         | 0.180  | 15.3       |
| a1                    | 198     | 11          | 3         | 8         | 28         | 0.165  | 14.1       |
| a7                    | 198     | 11          | 3         | 8         | 27         | 0.158  | 13.6       |
| boston                | 506     | 13          | 0         | 13        | 65         | 0.147  | 12.8       |
| pdgfr                 | 79      | 320         | 0         | 320       | 10         | 0.145  | 12.7       |
| sensory               | 576     | 11          | 0         | 11        | 69         | 0.136  | 12.0       |
| a2                    | 198     | 11          | 3         | 8         | 22         | 0.125  | 11.1       |
| kdd-coil-1            | 316     | 18          | 0         | 18        | 34         | 0.121  | 10.8       |
| triazines             | 186     | 60          | 0         | 60        | 20         | 0.120  | 10.8       |
| airfoild              | 1503    | 5           | 0         | 5         | 161        | 0.120  | 10.7       |
| treasury              | 1049    | 15          | 0         | 15        | 109        | 0.116  | 10.4       |
| mortgage              | 1049    | 15          | 0         | 15        | 106        | 0.112  | 10.1       |
| debutanizer           | 2394    | 7           | 0         | 7         | 240        | 0.111  | 10.0       |
| fuelCons              | 1764    | 37          | 12        | 25        | 164        | 0.103  | 9.3        |
| heat                  | 7400    | 11          | 3         | 8         | 664        | 0.099  | 9.0        |
| california            | 20640   | 8           | 0         | 8         | 1821       | 0.097  | 8.8        |
| AvailPwr              | 1802    | 15          | 7         | 8         | 157        | 0.095  | 8.7        |
| compactiv             | 8192    | 21          | 0         | 21        | 713        | 0.095  | 8.7        |
| cpuSm                 | 8192    | 12          | 0         | 12        | 713        | 0.095  | 8.7        |
| maxTorq               | 1802    | 32          | 13        | 19        | 129        | 0.077  | 7.2        |
| lungcancer-shedden    | 442     | 24          | 0         | 24        | 25         | 0.060  | 5.7        |
| space-ga              | 3107    | 6           | 0         | 6         | 173        | 0.059  | 5.6        |
| ConcrStr              | 1030    | 8           | 0         | 8         | 55         | 0.056  | 5.3        |
| Accel                 | 1732    | 14          | 3         | 11        | 89         | 0.054  | 5.1        |


(N: number of cases; p.total: number of attributes; p.nom: number of nominal attributes; p.num: number of numeric attributes; nRare: number of rare cases; %Rare: 100 × NRaro/N )).


# Tools

The experiments were performed in Python and used packages in R through the library [rpy2](https://rpy2.github.io/).

- Packages:

  - [Scikit-learn](https://scikit-learn.org/stable/)
    - BaggingRegressor
    - DecisionTreeRegressor
    - MLPRegressor
    - RandomForestRegressor
    - SVR
  - [XGBoost](https://xgboost.readthedocs.io/)
    - XGBoost
  - [smogn 0.1.2](https://pypi.org/project/smogn/)
    - SMOGN
  - [resreg 0.2](https://pypi.org/project/resreg/)
    - WERCS
  - [ImbalancedLearningRegression](https://pypi.org/project/ImbalancedLearningRegression/)
    - SMOTER
    - Random over-sampling 
    - Random under-sampling
    - Gaussian Noise Introduction


- Metrics:
  - [F1-score](https://github.com/rpribeiro/uba)
  - [SERA](https://github.com/nunompmoniz/IRon)

# References

Paula Branco, Rita P Ribeiro, and Luis Torgo. 2016. UBL: an R package for utility-based learning. arXiv preprint arXiv:1604.08079 (2016).
Paula Branco, Luis Torgo, and Rita P Ribeiro. 2019. Pre-processing approaches for imbalanced distributions in regression. Neurocomputing 343
(2019), 76–99. (https://arxiv.org/abs/1604.08079) 

Paula Oliveira Branco, Luís Torgo, and Rita Paula Ribeiro. 2017. SMOGN: a pre-processing approach for imbalanced regression. In First International
Workshop on Learning with Imbalanced Domains: Theory and Applications, Vol. 74. 36–50.(http://proceedings.mlr.press/v74/branco17a)

Luís Torgo, Rita P Ribeiro, Bernhard Pfahringer, and Paula Branco. 2013. Smote for regression. In Portuguese conference on artificial intelligence.
Springer, 378–389. (https://link.springer.com/chapter/10.1007/978-3-642-40669-0_33)

Rita P Ribeiro and Nuno Moniz. 2020. Imbalanced regression and extreme value prediction. Machine Learning 109, 9 (2020), 1803–1835. (https://link.springer.com/article/10.1007/s10994-020-05900-9)

Wu, Wenglei, Nicholas Kunz, and Paula Branco. "ImbalancedLearningRegression-A Python Package to Tackle the Imbalanced Regression Problem." Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Cham: Springer Nature Switzerland, 2022. (https://link.springer.com/chapter/10.1007/978-3-031-26422-1_48)
